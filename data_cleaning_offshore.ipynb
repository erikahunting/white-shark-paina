{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astral import LocationInfo\n",
    "from astral.sun import sun\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from pathlib import Path  \n",
    "import pytz\n",
    "from pytz import timezone\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import swifter\n",
    "from swifter import set_defaults\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_defaults(\n",
    "    npartitions=None,\n",
    "    dask_threshold=1,\n",
    "    scheduler=\"processes\",\n",
    "    progress_bar=True,\n",
    "    progress_bar_desc=None,\n",
    "    allow_dask_on_strings=True,\n",
    "    force_parallel=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standardized_datetime(row, originaltzstring):\n",
    "    \"\"\"\n",
    "    Given a row representing one time series \n",
    "    point from a corrected white shark archival tag \n",
    "    file and a str of the timezone of the timestamps, \n",
    "    returns a datetime object for the event in \n",
    "    Pacific/Honolulu time.\n",
    "    \"\"\"\n",
    "    originaltz = pytz.timezone(originaltzstring)\n",
    "    originaldt = dt.datetime(row[\"Year\"], row[\"Month\"], row[\"Day\"], row[\"Hour\"], row[\"Min\"], row[\"Sec\"], 0, originaltz)\n",
    "    return originaldt.astimezone(pytz.timezone(\"Pacific/Honolulu\"))\n",
    "    \n",
    "\n",
    "def get_time_of_day(hour):\n",
    "    \"\"\"\n",
    "    Given an int between 0 and 23 representing the\n",
    "    hour of the day, returns the time of day \n",
    "    corresponding to that hour in Hawaii e.g.\n",
    "    \"Dawn,\" \"Day,\" \"Dusk,\" or \"Night.\"\n",
    "    \"\"\"\n",
    "    sunrise = 6\n",
    "    sunset = 18\n",
    "\n",
    "    if (hour in range(0, sunrise - 1)) or (hour in range(sunset + 1, 24)):\n",
    "        return 'Night'\n",
    "    elif hour in range(sunrise - 1, sunrise + 1):\n",
    "        return 'Dawn'\n",
    "    elif hour in range(sunrise + 1, sunset - 1):\n",
    "        return 'Day'\n",
    "    elif hour in range(sunset - 1, sunset + 1):\n",
    "        return 'Dusk'\n",
    "    else:\n",
    "        return np.NaN\n",
    "\n",
    "\n",
    "def get_plot_data(filename): \n",
    "    \"\"\"\n",
    "    Given a filename to corrected archival White Shark tag\n",
    "    data, returns a pandas dataframe containing data for\n",
    "    plotting\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    # Get timezone of date/time\n",
    "    dateColName = df.columns[0]\n",
    "    originaltz = ''\n",
    "    if dateColName == \"Date(UTC-8)\":\n",
    "        originaltz = 'Etc/GMT+8' # why? no one knows\n",
    "    elif dateColName == \"Date(EST)\":\n",
    "        originaltz = 'UTC' # ehy? EST was mistake\n",
    "    elif dateColName == \"Date\":\n",
    "        originaltz = 'UTC'\n",
    "    else:\n",
    "        raise ValueError(\"Cannot processes timezone of Date column\" + dateColName)\n",
    "    \n",
    "    # Build standard datetime\n",
    "    df[\"Datetime (UTC-10)\"] = df.swifter.apply(lambda row: get_standardized_datetime(row, originaltz), axis=1)\n",
    "    \n",
    "    # add hour column\n",
    "    df[\"Hour (UTC-10)\"] = df[\"Datetime (UTC-10)\"].swifter.apply(lambda x: x.hour)\n",
    "    \n",
    "    # add time of day column\n",
    "    df[\"Time of Day\"] = df[\"Hour (UTC-10)\"].swifter.apply(get_time_of_day)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_filepaths_in_dir(dir_path):\n",
    "    \"\"\"\n",
    "    Given a directory path, return a list of files in the given directory.\n",
    "    >>> get_files_in_dir('./test')\n",
    "    ['test1.txt', 'test.txt']\n",
    "    \"\"\"\n",
    "    only_files = [join(dir_path, f) for f in listdir(dir_path) if isfile(join(dir_path, f))]\n",
    "    return only_files\n",
    "\n",
    "\n",
    "def filter_csvs(filepaths):\n",
    "    \"\"\"\n",
    "    Given a list of filepaths, returns a list containing only the csv filepaths \n",
    "    in the given list.\n",
    "    \"\"\"\n",
    "    csv_files = [f for f in filepaths if '.csv' in f]\n",
    "    return csv_files\n",
    "\n",
    "\n",
    "def get_shark_ID(filepath):\n",
    "    \"\"\"\n",
    "    Given string filepath, returns 7 digit shark ID in filepath\n",
    "    name.\n",
    "    \"\"\"\n",
    "    # pattern matches any sequence of 7 digits\n",
    "    pattern = '\\\\d{7}'\n",
    "\n",
    "    sharkIDMatch = re.search(pattern, filepath)\n",
    "    assert sharkIDMatch, 'Could not find 7 digit ID in filepath: {}'.format(filepath)\n",
    "    \n",
    "    sharkID = sharkIDMatch.group(0)\n",
    "    return sharkID + '00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from manuel digging:\n",
    "# sample rate on 190000400 is once every 2 min\n",
    "# 190400900 is once every min\n",
    "# 190502800 is once every min\n",
    "# 190600200 is once every min\n",
    "# 190601200 is oncer every 15 sec\n",
    "# 190900200 is once every 10 sec\n",
    "# 191909200 is once every 57 m 36 s (effectively 1/hour)\n",
    "# So reampling everything to once per house will be good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   eventid      6 non-null      int64  \n",
      " 1   tagnumber    6 non-null      object \n",
      " 2   ptt          6 non-null      int64  \n",
      " 3   taggingdate  6 non-null      object \n",
      " 4   length       6 non-null      float64\n",
      " 5   sex          6 non-null      object \n",
      " 6   firstdate    6 non-null      object \n",
      " 7   lastdate     6 non-null      object \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 512.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": "datetime.datetime(2001, 1, 3, 0, 0)"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all Hawaii white shark archival files\n",
    "files = filter_csvs(get_filepaths_in_dir('./original_data_open_ocean'))\n",
    "\n",
    "# metadata for Hawaii white sharks with Id, tag number, \n",
    "# ptt, tagging date, length, sex, and first/last date\n",
    "# that shark was in Hawaiian lees\n",
    "meta_df = pd.read_csv('./ws_hawaiionly_ssm_archivals_dateranges_2022apr18.csv')\n",
    "\n",
    "meta_df.info()\n",
    "\n",
    "row = meta_df.iloc[0]\n",
    "date = row['firstdate']\n",
    "date_str = date[0:10]\n",
    "date_str\n",
    "\n",
    "datetime_object = datetime.strptime(date_str, '%m/%d/%Y')\n",
    "datetime_object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Provides a `DateTimeRange` class, which is used for managing ranges of datetimes.\"\"\"\n",
    "import datetime\n",
    "\n",
    "class DateTimeRange(object):\n",
    "    \"\"\"Represents a range of datetimes, with a start and (optionally) an end.\n",
    "       \n",
    "       Basically implements most of the methods on a standard sequence data type to provide\n",
    "       some lovely syntactic sugar. Specifically, you can iterate on this, index it, slice it,\n",
    "       use the in operator, reverse it, and use it in a boolean context to see if there is any\n",
    "       time in between the start and end.\"\"\"\n",
    "    DEFAULT_STEP = datetime.timedelta(seconds=1)\n",
    "    \n",
    "    def __init__(self, start, end=None, step=DEFAULT_STEP, *args, **kwargs):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.step = step\n",
    "        return super(DateTimeRange, self).__init__(*args, **kwargs)\n",
    "    \n",
    "    def __contains__(self, item):\n",
    "        \"\"\"Returns whether or not the passed datetime is within the range. Does not take into\n",
    "           account the stride length from `self.step` -- if you need that use dateutil's rrule\n",
    "           instead.\"\"\"\n",
    "        if self.end is None:\n",
    "            # The range never ends, so we just need to check `item` is beyond the start\n",
    "            return (self.start <= item)\n",
    "        else:\n",
    "            return (self.start <= item <= self.end)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\"Returns a generator which will yield datetime objects within the range, incrementing\n",
    "           with `self.step` as its stride length on each iteration.\"\"\"\n",
    "        value = self.start\n",
    "        while (value in self):\n",
    "            yield value\n",
    "            value += self.step\n",
    "    \n",
    "    def __reversed__(self):\n",
    "        \"\"\"Reverse iterator yielding the datetime objects within the range in reverse. Similarly\n",
    "           to the forward-iterator, decrements (rather than increments) by `self.step` each time.\n",
    "           \n",
    "           This can only be called if an end is defined.\"\"\"\n",
    "        assert self.end is not None, 'Reverse iteration is not supported without an end'\n",
    "        \n",
    "        value = self.end\n",
    "        while (value in self):\n",
    "            yield value\n",
    "            value -= self.step\n",
    "    \n",
    "    def __nonzero__(self):\n",
    "        \"\"\"Returns whether the date range covers a length of time (i.e. the end value is beyond\n",
    "           the start). If no end is defined, always returns True as the range continues forever.\"\"\"\n",
    "        return ((not self.end) or (self.end > self.start))\n",
    "    \n",
    "    def __get_slice(self, start, stop, step=None):\n",
    "        \"\"\"Internal method for slicing the date range. Use the standard slicing syntax as the\n",
    "           external interface.\"\"\"\n",
    "        indices = (xrange(start, stop, step) if step is not None else xrange(start, stop))\n",
    "        result = []\n",
    "        \n",
    "        for index in indices:\n",
    "            try:\n",
    "                result.append(self[index])\n",
    "            except IndexError:\n",
    "                pass\n",
    "        return result\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"Returns the n'th datetime from the range, using `self.step` to determine the\n",
    "           increment. Does not calculate every datetime up until the index, but rather\n",
    "           multiplies the step value by the index to achieve the same result more efficiently.\n",
    "           \n",
    "           Negative indexing is only supported if an end is defined. Also supports slicing -- the\n",
    "           same rule regarding negative indexing still applying.\"\"\"\n",
    "        if isinstance(key, tuple):\n",
    "            # Multiple indices\n",
    "            return [self[i] for i in key]\n",
    "        elif isinstance(key, slice):\n",
    "            # Slicing\n",
    "            return self.__get_slice(start=key.start, stop=key.stop, step=key.step)\n",
    "        else:\n",
    "            # Regular indexing\n",
    "            if key < 0:\n",
    "                # Reverse-indexing\n",
    "                assert self.end is not None, 'Negative indexing is not supported without an end'\n",
    "                value = (self.end - (self.step * key))\n",
    "            else:\n",
    "                # Forward-indexing\n",
    "                value = (self.start + (self.step * key))\n",
    "            \n",
    "            # Check that the value is in the range; return it if it is, raise IndexError if not\n",
    "            if value in self:\n",
    "                return value\n",
    "            else:\n",
    "                raise IndexError('index out of range')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be9335f934d8481c87de9196456141f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Dask Apply:   0%|          | 0/32 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296a01ecf8a34f00ba22dfa16ecfef9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Pandas Apply:   0%|          | 0/133543 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6007207854334c76847f14750f9d9fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Pandas Apply:   0%|          | 0/133543 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25616a9926d47fe972baa13dcf338b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Dask Apply:   0%|          | 0/32 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa2aa0063db4e42ace3ee658bd43337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Pandas Apply:   0%|          | 0/275570 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab9b5c2f1d2406486403d0fbd3277ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Pandas Apply:   0%|          | 0/275570 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e258939e00498087a3e76affa7f0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Dask Apply:   0%|          | 0/32 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c36669703e7478094469f8fadebb393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Pandas Apply:   0%|          | 0/443420 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd675c1a7ddd4a80a47f097e220204c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Pandas Apply:   0%|          | 0/443420 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87a5f97fd2146b6862c11216048317d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Dask Apply:   0%|          | 0/32 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0084fef21f6d4c81871aaacb3b2828d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Pandas Apply:   0%|          | 0/335228 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0adabc71004e46329167b3a1d54de0e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Pandas Apply:   0%|          | 0/335228 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de5c9b33d267401ab1e97d2167ccfae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Dask Apply:   0%|          | 0/32 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b018711f877b4f3d84ca5120ab087b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Dask Apply:   0%|          | 0/32 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4e6f6031d941bda4687db515a2d533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Dask Apply:   0%|          | 0/32 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d7cb7b263545d59fd1e17a8932a91e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Dask Apply:   0%|          | 0/32 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a76ed20169b4183a0bfd8351751e45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Dask Apply:   0%|          | 0/32 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2f84c4ed5a4a078954da52698929b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Dask Apply:   0%|          | 0/32 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "strptime() argument 1 must be str, not Series",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m arrival_date_str \u001b[38;5;241m=\u001b[39m arrival_date[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m10\u001b[39m]\n\u001b[1;32m     43\u001b[0m departure_date_str \u001b[38;5;241m=\u001b[39m departure_date[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m10\u001b[39m]\n\u001b[0;32m---> 45\u001b[0m arrival_datetime_object \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrival_date_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm/\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m departure_datetime_object \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mstrptime(departure_date_str, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# pull out dates not in dateRange(arrive in HI, leave HI)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: strptime() argument 1 must be str, not Series"
     ]
    }
   ],
   "source": [
    "# build a master dataframe containing these columns for all Hawaii white sharks\n",
    "columns = [\"Id\", \"Datetime (UTC-10)\", \"Hour (UTC-10)\", \"Time of Day\", \"Depth(m)\", \"External Temp (c)\", \"Sex\", \"Shark Length (cm)\"] # add all the other stuff just incase\n",
    "dfs = []\n",
    "\n",
    "for file in sorted(files):\n",
    "    df = get_plot_data(file)\n",
    "    shark_id = get_shark_ID(file)\n",
    "    df['Id'] = shark_id\n",
    "    sex = meta_df[meta_df['eventid'] == int(shark_id) ]['sex'].iloc[0]\n",
    "    df['Sex'] = sex\n",
    "    df['External Temp (c)'] = df['ExtTemp(C)']\n",
    "    df['Shark Length (cm)'] = meta_df[meta_df['eventid'] == int(shark_id) ]['length'].iloc[0]\n",
    "    df = df[columns]\n",
    "\n",
    "    # uncomment for re-sampling\n",
    "    # # standardize sample frequency in master dataframe\n",
    "    # if shark_id == '190000400':\n",
    "    #     df = df.iloc[::30, :]\n",
    "    # elif (shark_id == '190400900') or (shark_id == '190502800') or (shark_id == '190600200'):\n",
    "    #     df = df.iloc[::60, :]\n",
    "    # elif shark_id == '190601200':\n",
    "    #     df = df.iloc[::240, :]\n",
    "    # elif shark_id == '190900200':\n",
    "    #     df = df.iloc[::360, :]\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "# combined = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "#only contains data for open ocean\n",
    "filtered_dfs = []\n",
    "\n",
    "# cut Hawaii and Monterey dates from tag data to leave only open ocean data for each shark\n",
    "for df in dfs:\n",
    "    shark_id = df['Id'][0]\n",
    "\n",
    "    # dates in Paina\n",
    "    shark_meta_data = meta_df.loc[meta_df['eventid'] == int(shark_id)]\n",
    "    arrival_date = shark_meta_data['firstdate']\n",
    "    departure_date = shark_meta_data['lastdate']\n",
    "\n",
    "    arrival_date_str = arrival_date[0:10]\n",
    "    departure_date_str = departure_date[0:10]\n",
    "\n",
    "    arrival_datetime_object = datetime.strptime(arrival_date_str, '%m/%d/%Y')\n",
    "    departure_datetime_object = datetime.strptime(departure_date_str, '%m/%d/%Y')\n",
    "\n",
    "    # pull out dates not in dateRange(arrive in HI, leave HI)\n",
    "    filtered_df = df.loc[df['Datetime (UTC-10)'] not in DateTimeRange(arrival_date, departure_date)]\n",
    "    filtered_dfs.append(filtered_df)\n",
    "\n",
    "combined = pd.concat(filtered_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Time of Day Using Astral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test inclusivity of class\n",
    "one_hr = dt.timedelta(hours=1)\n",
    "sunrise = dt.datetime(2020, 3, 21, 6, 0, 0).astimezone(pytz.timezone(\"Pacific/Honolulu\"))\n",
    "sunset = dt.datetime(2020, 3, 21, 18, 0, 0).astimezone(pytz.timezone(\"Pacific/Honolulu\"))\n",
    "ran = DateTimeRange(sunrise + one_hr, sunset - one_hr)\n",
    "(sunset - one_hr) in ran # TRUE if DateTimeRange is end inclusive, FALSE else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_of_day_astral(date_time, lat, lon):\n",
    "    \"\"\"\n",
    "    Given a datetime object in Hawaii time (UTC-10), \n",
    "    an int representing latitude, and an int representing \n",
    "    longitude, returns returns local apparent the time \n",
    "    of day corresponding to that hour in Hawaii e.g.\n",
    "    \"Dawn,\" \"Day,\" \"Dusk,\" or \"Night.\"\n",
    "    \"\"\"\n",
    "    # date_time = date_time.astimezone(pytz.timezone(\"Pacific/Honolulu\")) # run this line if input date_time os not in Hawaii time\n",
    "    if (date_time.date is None) or (date_time.year is None) or (date_time.month is None) or (date_time.day is None):\n",
    "        raise ValueError(\"Cannot processes date with value: \", date)\n",
    "\n",
    "    date_time_std = dt.datetime(date_time.year, date_time.month, date_time.day, date_time.hour, date_time.minute, date_time.second, 0, pytz.UTC)\n",
    "    date_time_std = date_time_std.replace(tzinfo=pytz.timezone(\"Pacific/Honolulu\"))\n",
    "\n",
    "    location = LocationInfo(\"Honolulu\", \"Hawaii\", \"Pacific/Honolulu\", lat, lon)\n",
    "    s = sun(location.observer, date=datetime.date(date_time.year, date_time.month, date_time.day), tzinfo=location.timezone) \n",
    "\n",
    "    # time of day\n",
    "    sunrise = s[\"sunrise\"]\n",
    "    sunrise_std = dt.datetime(sunrise.year, sunrise.month, sunrise.day, sunrise.hour, sunrise.minute, sunrise.second, 0, pytz.UTC)\n",
    "    sunrise_std = sunrise_std.replace(tzinfo=pytz.timezone(\"Pacific/Honolulu\"))\n",
    "\n",
    "    sunset = s[\"sunset\"]\n",
    "    sunset_std = dt.datetime(sunset.year, sunset.month, sunset.day, sunset.hour, sunset.minute, sunset.second, 0, pytz.UTC)\n",
    "    sunset_std = sunset_std.replace(tzinfo=pytz.timezone(\"Pacific/Honolulu\"))\n",
    "\n",
    "    one_hr = dt.timedelta(hours=1)\n",
    "    one_s = dt.timedelta(seconds=1)\n",
    "\n",
    "    midnight = dt.datetime(date_time.year, date_time.month, date_time.day, 0, 0, 0, 0, pytz.UTC)\n",
    "    midnight = midnight.replace(tzinfo=pytz.timezone(\"Pacific/Honolulu\"))\n",
    "    \n",
    "    pre_midnight = dt.datetime(date_time.year, date_time.month, date_time.day, 23, 59, 59, 0, pytz.UTC)\n",
    "    pre_midnight = pre_midnight.replace(tzinfo=pytz.timezone(\"Pacific/Honolulu\"))\n",
    "    \n",
    "    # DateTimeRange is inclusive of start and stop inputs\n",
    "    if (date_time_std in DateTimeRange(midnight, sunrise_std - one_hr)) or (date_time_std in DateTimeRange(sunset_std + one_hr, pre_midnight)):\n",
    "        return 'Night'\n",
    "    elif date_time_std in DateTimeRange(sunrise_std - one_hr + one_s, sunrise_std + one_hr):\n",
    "        return 'Dawn'\n",
    "    elif date_time_std in DateTimeRange(sunrise_std + one_hr + one_s, sunset_std - one_hr):\n",
    "        return \"Day\"\n",
    "    elif date_time_std in DateTimeRange(sunset_std - one_hr + one_s, sunset_std + one_hr - one_s):\n",
    "        return 'Dusk'\n",
    "    else:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_lat = pd.read_csv('./ws_hawaiionly_ssm_archivals_2022apr12.csv')[\"latitude\"].mean()\n",
    "avg_lon = pd.read_csv('./ws_hawaiionly_ssm_archivals_2022apr12.csv')[\"longitude\"].mean()\n",
    "location = LocationInfo(\"Honolulu\", \"Hawaii\", \"Pacific/Honolulu\", avg_lat, avg_lon)\n",
    "s = sun(location.observer, dt.datetime.now(), tzinfo=location.timezone) \n",
    "\n",
    "pre_midnight = dt.datetime(dt.datetime.now().year, dt.datetime.now().month, dt.datetime.now().day, 23, 59, 59, 0, pytz.UTC)\n",
    "pre_midnight = pre_midnight.replace(tzinfo=pytz.timezone(\"Pacific/Honolulu\"))\n",
    "\n",
    "s[\"sunrise\"], pre_midnight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a \"Time of Day (Astral)\" column\" - time of day (\"Dusk,\" \"Dawn,\" etc.) calculated by the Astral API\n",
    "\n",
    "# can parallelize with multiprocessing later https://stackoverflow.com/questions/45545110/make-pandas-dataframe-apply-use-all-cores \n",
    "avg_lat = pd.read_csv('./ws_hawaiionly_ssm_archivals_2022apr12.csv')[\"latitude\"].mean()\n",
    "avg_lon = pd.read_csv('./ws_hawaiionly_ssm_archivals_2022apr12.csv')[\"longitude\"].mean()\n",
    "combined[\"Time of Day (Astral)\"] = combined.swifter.apply(lambda x: get_time_of_day_astral(x[\"Datetime (UTC-10)\"], avg_lat, avg_lon), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.info()\n",
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Orginal Time of Day with Time of Day Computed Using Astral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[\"Time of Day\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[\"Time of Day (Astral)\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for NaN\n",
    "combined[combined['Time of Day'].isna()]\n",
    "combined[combined['Time of Day (Astral)'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv('./master.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "name": "python3102jvsc74a57bd098590ff4fe04c8543246b2a01debd3de3c5ca9b666f43f1fa87d5110c692004c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}